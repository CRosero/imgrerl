{"collect/return": 200.89023226313293, "collect/steps": 1000.0, "collect/total_steps": 1006000.0, "train/qf1_loss": 0.08435240879654884, "train/qf2_loss": 0.08339455939829349, "train/policy_loss": -33.601065483093265, "train/policy_entropy": -5.9782592391967775, "train/alpha": 0.007025833195075393, "train/time": 34.52706289291382, "eval/return": 208.19305696089287, "eval/steps": 1000.0, "_timestamp": 1678744849.5196452, "_runtime": 38493.96806430817, "_step": 1000, "_wandb": {"runtime": 38494}}