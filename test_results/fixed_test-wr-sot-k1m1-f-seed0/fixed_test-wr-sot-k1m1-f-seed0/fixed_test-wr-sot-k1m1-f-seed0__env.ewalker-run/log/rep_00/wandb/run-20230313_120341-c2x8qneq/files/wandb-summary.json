{"collect/return": 280.86777814663947, "collect/steps": 1000.0, "collect/total_steps": 1006000.0, "train/qf1_loss": 0.1375630248337984, "train/qf2_loss": 0.13837871469557286, "train/policy_loss": -38.99691967010498, "train/policy_entropy": -5.991639914512635, "train/alpha": 0.008844453152269125, "train/time": 33.34708547592163, "eval/return": 278.9958724398166, "eval/steps": 1000.0, "_timestamp": 1678742759.262772, "_runtime": 37337.2642891407, "_step": 1000, "_wandb": {"runtime": 37337}}