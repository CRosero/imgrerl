{"collect/return": 324.50973658263683, "collect/steps": 1000.0, "collect/total_steps": 1006000.0, "train/qf1_loss": 0.24629130691289902, "train/qf2_loss": 0.24413725078105927, "train/policy_loss": -46.75951602935791, "train/policy_entropy": -5.9622593688964844, "train/alpha": 0.01224517110735178, "train/time": 34.11632251739502, "eval/return": 319.433273140667, "eval/steps": 1000.0, "_timestamp": 1678767605.2425585, "_runtime": 37480.14940357208, "_step": 1000, "_wandb": {"runtime": 37480}}