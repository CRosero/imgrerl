{"collect/return": 79.12650409899652, "collect/steps": 1000.0, "collect/total_steps": 1006000.0, "train/qf1_loss": 0.12624576613306998, "train/qf2_loss": 0.12582939729094506, "train/policy_loss": -19.036611614227294, "train/policy_entropy": -5.957555356025696, "train/alpha": 0.006808734773658216, "train/time": 34.0739631652832, "eval/return": 128.24239945684093, "eval/steps": 1000.0, "_timestamp": 1678776465.0508418, "_runtime": 37415.09263777733, "_step": 1000, "_wandb": {"runtime": 37415}}